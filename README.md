# Email Phishing Classifier using Neural Networks & Backpropagation

A deep learning project that classifies emails as **Safe** or **Phishing** using neural networks with backpropagation algorithm, implemented in Google Colab.

## üîç Overview

This project implements a neural network classifier that detects phishing emails using backpropagation learning algorithm. The model learns to distinguish between legitimate (safe) emails and malicious phishing attempts through supervised learning in Google Colab.

**Binary Classification Problem:**
- **Class 0**: Safe Mail (Legitimate emails)
- **Class 1**: Phishing Mail (Malicious/Fraudulent emails)

## ‚ú® Features

- **Neural Network Implementation**: Custom multilayer perceptron with backpropagation
- **Binary Classification**: Safe vs Phishing email detection
- **Feature Engineering**: Advanced text preprocessing and vectorization
- **Backpropagation Learning**: Gradient descent optimization
- **Real-time Testing**: Interactive phishing detection system
- **Performance Visualization**: Training curves and confusion matrices
- **Cross-validation**: Robust model evaluation

## üìä Dataset

### Phishing Email Dataset Structure
```
Total Samples: ~10,000 emails
‚îú‚îÄ‚îÄ Safe Emails: ~6,000 (60%)
‚îî‚îÄ‚îÄ Phishing Emails: ~4,000 (40%)
```

### Dataset Features
- **Email Subject**: Subject line analysis
- **Email Body**: Content analysis for phishing indicators
- **URL Analysis**: Suspicious link detection
- **Sender Information**: Domain and header analysis

### Sample Data Format
```csv
email_id,subject,body,sender,label
1,"Account Verification","Please verify...",bank@email.com,0
2,"Urgent: Claim Prize","You won $1000...",noreply@fake.com,1
```

## üöÄ Installation

### Google Colab Setup

```python
# Install required packages
!pip install tensorflow keras pandas numpy matplotlib seaborn scikit-learn nltk

# Import essential libraries
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import classification_report, confusion_matrix
import nltk
nltk.download('stopwords')
nltk.download('punkt')
```

## üß† Neural Network Architecture

### Network Structure
```
Input Layer (1000 neurons) - TF-IDF features
    ‚Üì
Hidden Layer 1 (512 neurons) - ReLU activation
    ‚Üì
Dropout Layer (0.3) - Regularization
    ‚Üì
Hidden Layer 2 (256 neurons) - ReLU activation
    ‚Üì
Dropout Layer (0.3) - Regularization
    ‚Üì
Hidden Layer 3 (128 neurons) - ReLU activation
    ‚Üì
Output Layer (1 neuron) - Sigmoid activation
```

### Model Implementation
```python
def create_phishing_classifier():
    model = keras.Sequential([
        # Input layer
        layers.Dense(512, activation='relu', input_shape=(1000,)),
        layers.Dropout(0.3),
        
        # Hidden layers
        layers.Dense(256, activation='relu'),
        layers.Dropout(0.3),
        
        layers.Dense(128, activation='relu'),
        layers.Dropout(0.2),
        
        # Output layer for binary classification
        layers.Dense(1, activation='sigmoid')
    ])
    
    # Compile with backpropagation optimizer
    model.compile(
        optimizer='adam',  # Adam optimizer for backpropagation
        loss='binary_crossentropy',
        metrics=['accuracy', 'precision', 'recall']
    )
    
    return model
```

## üìñ Usage

### 1. Data Preprocessing

```python
def preprocess_email_data(df):
    """
    Preprocess email data for phishing detection
    """
    # Combine subject and body for full text analysis
    df['full_text'] = df['subject'].fillna('') + ' ' + df['body'].fillna('')
    
    # Clean text data
    def clean_text(text):
        import re
        # Convert to lowercase
        text = text.lower()
        # Remove URLs (common in phishing)
        text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)
        # Remove special characters
        text = re.sub(r'[^a-zA-Z\s]', '', text)
        # Remove extra whitespace
        text = ' '.join(text.split())
        return text
    
    df['cleaned_text'] = df['full_text'].apply(clean_text)
    return df

# Load and preprocess data
df = pd.read_csv('phishing_emails.csv')
df = preprocess_email_data(df)
```

### 2. Feature Extraction

```python
# TF-IDF Vectorization for neural network input
vectorizer = TfidfVectorizer(
    max_features=1000,  # Input layer size
    stop_words='english',
    ngram_range=(1, 2),  # Unigrams and bigrams
    max_df=0.95,
    min_df=2
)

# Transform text to numerical features
X = vectorizer.fit_transform(df['cleaned_text']).toarray()
y = df['label'].values  # 0: Safe, 1: Phishing

# Normalize features for better neural network performance
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
```

### 3. Model Training with Backpropagation

```python
# Split data for training and testing
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42, stratify=y
)

# Create and train the model
model = create_phishing_classifier()

# Training with backpropagation
history = model.fit(
    X_train, y_train,
    batch_size=32,
    epochs=100,
    validation_split=0.2,
    verbose=1,
    callbacks=[
        keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),
        keras.callbacks.ReduceLROnPlateau(patience=5, factor=0.5)
    ]
)
```

## üîÑ Backpropagation Algorithm

### Mathematical Foundation

The backpropagation algorithm updates weights using gradient descent:

```python
# Forward Pass
def forward_pass(X, weights, biases):
    """
    Forward propagation through the network
    """
    activations = [X]
    z_values = []
    
    for i in range(len(weights)):
        z = np.dot(activations[-1], weights[i]) + biases[i]
        z_values.append(z)
        
        if i < len(weights) - 1:  # Hidden layers
            a = relu(z)
        else:  # Output layer
            a = sigmoid(z)
        
        activations.append(a)
    
    return activations, z_values

# Backward Pass
def backward_pass(activations, z_values, y_true, weights):
    """
    Backpropagation to compute gradients
    """
    m = len(y_true)
    gradients_w = []
    gradients_b = []
    
    # Output layer error
    delta = activations[-1] - y_true.reshape(-1, 1)
    
    # Backpropagate through layers
    for i in reversed(range(len(weights))):
        # Compute gradients
        dW = (1/m) * np.dot(activations[i].T, delta)
        db = (1/m) * np.sum(delta, axis=0)
        
        gradients_w.insert(0, dW)
        gradients_b.insert(0, db)
        
        if i > 0:  # Not input layer
            delta = np.dot(delta, weights[i].T) * relu_derivative(z_values[i-1])
    
    return gradients_w, gradients_b
```

### Learning Process Visualization

```python
def plot_training_history(history):
    """
    Visualize backpropagation learning process
    """
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # Training & Validation Loss
    axes[0, 0].plot(history.history['loss'], label='Training Loss')
    axes[0, 0].plot(history.history['val_loss'], label='Validation Loss')
    axes[0, 0].set_title('Model Loss (Backpropagation Learning)')
    axes[0, 0].legend()
    
    # Training & Validation Accuracy
    axes[0, 1].plot(history.history['accuracy'], label='Training Accuracy')
    axes[0, 1].plot(history.history['val_accuracy'], label='Validation Accuracy')
    axes[0, 1].set_title('Model Accuracy')
    axes[0, 1].legend()
    
    # Precision & Recall
    axes[1, 0].plot(history.history['precision'], label='Precision')
    axes[1, 0].plot(history.history['recall'], label='Recall')
    axes[1, 0].set_title('Precision & Recall')
    axes[1, 0].legend()
    
    plt.tight_layout()
    plt.show()

plot_training_history(history)
```

## üß™ Testing & Results

### Test Cases for Phishing Detection

```python
def test_phishing_classifier(model, vectorizer, scaler):
    """
    Test the model with sample emails
    """
    test_cases = [
        {
            'email': "Dear Customer, Your account will be suspended. Click here to verify: http://fake-bank.com/login",
            'expected': 'Phishing',
            'type': 'URL Phishing'
        },
        {
            'email': "Meeting scheduled for tomorrow at 2 PM in conference room A. Please confirm your attendance.",
            'expected': 'Safe',
            'type': 'Legitimate Business Email'
        },
        {
            'email': "URGENT: You have won $10,000! Send your bank details immediately to claim your prize!",
            'expected': 'Phishing',
            'type': 'Prize Scam'
        },
        {
            'email': "Thank you for your purchase. Your order #12345 will be delivered within 3-5 business days.",
            'expected': 'Safe',
            'type': 'Order Confirmation'
        },
        {
            'email': "Your PayPal account has been limited. Please update your information at paypaI-security.com",
            'expected': 'Phishing',
            'type': 'Brand Impersonation'
        }
    ]
    
    print("üîç PHISHING DETECTION TEST RESULTS\n")
    print("="*70)
    
    correct_predictions = 0
    
    for i, test_case in enumerate(test_cases, 1):
        # Preprocess and predict
        cleaned_email = preprocess_email_text(test_case['email'])
        email_vector = vectorizer.transform([cleaned_email]).toarray()
        email_scaled = scaler.transform(email_vector)
        
        prediction_prob = model.predict(email_scaled)[0][0]
        prediction = 'Phishing' if prediction_prob > 0.5 else 'Safe'
        confidence = prediction_prob if prediction == 'Phishing' else (1 - prediction_prob)
        
        # Check if correct
        is_correct = prediction == test_case['expected']
        if is_correct:
            correct_predictions += 1
        
        # Display results
        status = "‚úÖ CORRECT" if is_correct else "‚ùå INCORRECT"
        print(f"Test Case {i}: {test_case['type']}")
        print(f"Email: {test_case['email'][:60]}...")
        print(f"Expected: {test_case['expected']} | Predicted: {prediction}")
        print(f"Confidence: {confidence:.2%} | Status: {status}")
        print("-" * 70)
    
    accuracy = correct_predictions / len(test_cases)
    print(f"\nüéØ Test Accuracy: {accuracy:.2%} ({correct_predictions}/{len(test_cases)})")
    
    return accuracy

# Run tests
test_accuracy = test_phishing_classifier(model, vectorizer, scaler)
```

### Interactive Phishing Detection

```python
def detect_phishing_interactive():
    """
    Interactive phishing detection for real-time testing
    """
    print("üõ°Ô∏è  Real-time Phishing Email Detector")
    print("Enter 'quit' to exit\n")
    
    while True:
        email_text = input("Enter email text to analyze: ")
        
        if email_text.lower() == 'quit':
            break
        
        # Process and predict
        cleaned_text = preprocess_email_text(email_text)
        email_vector = vectorizer.transform([cleaned_text]).toarray()
        email_scaled = scaler.transform(email_vector)
        
        prediction_prob = model.predict(email_scaled, verbose=0)[0][0]
        
        if prediction_prob > 0.5:
            risk_level = "üö® HIGH RISK - PHISHING DETECTED"
            confidence = prediction_prob
        else:
            risk_level = "‚úÖ SAFE EMAIL"
            confidence = 1 - prediction_prob
        
        print(f"\nüìä Analysis Results:")
        print(f"Classification: {risk_level}")
        print(f"Confidence: {confidence:.2%}")
        print(f"Phishing Probability: {prediction_prob:.3f}")
        print("-" * 50)

# Run interactive detector
detect_phishing_interactive()
```

## üìà Model Evaluation

### Performance Metrics

```python
# Evaluate model on test set
test_predictions = model.predict(X_test)
test_predictions_binary = (test_predictions > 0.5).astype(int)

# Calculate metrics
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

accuracy = accuracy_score(y_test, test_predictions_binary)
precision = precision_score(y_test, test_predictions_binary)
recall = recall_score(y_test, test_predictions_binary)
f1 = f1_score(y_test, test_predictions_binary)

print("üéØ FINAL MODEL PERFORMANCE")
print("="*40)
print(f"Accuracy:  {accuracy:.4f} ({accuracy:.2%})")
print(f"Precision: {precision:.4f} ({precision:.2%})")
print(f"Recall:    {recall:.4f} ({recall:.2%})")
print(f"F1-Score:  {f1:.4f} ({f1:.2%})")
```

### Confusion Matrix Visualization

```python
# Create confusion matrix
cm = confusion_matrix(y_test, test_predictions_binary)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=['Safe', 'Phishing'],
            yticklabels=['Safe', 'Phishing'])
plt.title('Phishing Detection Confusion Matrix')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()

# Calculate specific metrics
tn, fp, fn, tp = cm.ravel()
print(f"\nDetailed Results:")
print(f"True Negatives (Safe emails correctly identified): {tn}")
print(f"False Positives (Safe emails marked as phishing): {fp}")
print(f"False Negatives (Phishing emails missed): {fn}")
print(f"True Positives (Phishing emails caught): {tp}")
```

## üéØ Expected Results

### Typical Performance Metrics
- **Accuracy**: 96-98%
- **Precision**: 94-97%
- **Recall**: 93-96%
- **F1-Score**: 94-96%

### Training Characteristics
- **Epochs to Convergence**: 50-80 epochs
- **Training Time**: 5-10 minutes on Colab GPU
- **Validation Loss**: Typically < 0.1

## üöÄ Future Enhancements

- [ ] **Advanced Architectures**: LSTM/GRU for sequential analysis
- [ ] **Transfer Learning**: Pre-trained language models (BERT)
- [ ] **Feature Engineering**: URL analysis, header inspection
- [ ] **Real-time Integration**: Email client plugins
- [ ] **Adversarial Training**: Robust against sophisticated attacks
